# -*- coding: utf-8 -*-
"""Copy of DataScience_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ioYk51nCQrk40bJhWHYuXx1El7SiKVq7

Importing Dataset
"""

import pandas as pd
data = pd.read_csv("sample_data/US_Accidents_Dec20_updated.csv")

data.dtypes

data.info()

data = data.drop(columns=['Description',	'Number',	'Street',	'Side','Zipcode','Country','Airport_Code','Weather_Timestamp','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight'])

data.shape

data.info()

data['mean_Lat'] = (data['Start_Lat']+ data['End_Lat'])/2

data['mean_Lng'] = (data['Start_Lng']+ data['End_Lng'])/2

data=data.drop(columns=['Start_Lat',	'Start_Lng',	'End_Lat',	'End_Lng'])

from numpy import nan
data['Timezone'] = data['Timezone'].replace(nan,'US/Pacific')
from datetime import datetime
from pytz import timezone
for index,row in data.iterrows():
  datetime_obj = datetime.strptime(row['Start_Time'], "%d-%m-%Y %H:%M")
  datetime_obj_utc = datetime_obj.replace(tzinfo=timezone(row['Timezone']))
data['Start_Time'] = datetime.now(timezone("data['Timezone']"))

data=data.drop(columns=['Description',	'Number',	'Street',	'Side',	'Zipcode','Country','Airport_Code','Weather_Timestamp'])

data=data.drop(columns=['Civil_Twilight','Nautical_Twilight','Astronomical_Twilight'])

print(data.isnull().sum())

import matplotlib.pyplot as plt
states_data = pd.DataFrame(data['State'].value_counts()).reset_index().rename(columns={'index':'State','State':'Cases'})
top_states=states_data.head(10)
plt.bar(top_states['State'],top_states['Cases'])

import matplotlib.pyplot as plt
county_data = pd.DataFrame(data['County'].value_counts()).reset_index().rename(columns={'index':'County','County':'Cases'})
county_data=county_data.head(10)
plt.bar(county_data['County'],county_data['Cases'])

county_data

data.nunique()

data.shape

"""Geospatial Visualization """

# Accidents by State
import seaborn as sns
sns.set(style="darkgrid")
sns.histplot(data=states_data, x="Cases")
plt.show();

# Build the choropleth (using plotly-dynamic/interactive map)
import plotly.express as px
import plotly.graph_objects as go
fig = go.Figure(data=go.Choropleth(
    locations=states_data['State'], # Spatial coordinates
    z = states_data['Cases'].astype(float), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale = 'reds',
    colorbar_title = "Number of Accidents",
))

fig.update_layout(
    title_text = 'Road Accidents by State',
    geo_scope='usa', # limite map scope to USA
)

fig.show()

# Accidents by severity 
High_Severity = data[data['Severity']==4]
# using plotly
import plotly.graph_objects as go
import pandas as pd
High_Severity['text'] = High_Severity['County'] + '' + High_Severity['City'] + ', ' + High_Severity['State'] + '' + 'Severity: ' + High_Severity['Severity'].astype(str)

fig = go.Figure(data=go.Scattergeo(
        lon = High_Severity['mean_Lng'],
        lat = High_Severity['mean_Lat'],
        text = High_Severity['text'],
        mode = 'markers',
        marker=dict(
            color='rgba(135, 206, 250, 0.5)',
            size=1,
            line=dict(
                color='MediumPurple',
                width=0.5
            )
        ),
        ))

fig.update_layout(
        title = 'Most severe accidents across US',
        geo_scope='usa',
    )
fig.show()

#Time series visualization 
#import plotly.plotly as py
from pandas import read_csv
from matplotlib import pyplot
from datetime import datetime
data2=data
data2['End_Time'] = pd.to_datetime(data['End_Time'],format='%Y-%m-%d %H:%M:%S', errors='coerce')
data2 = data2.dropna(subset=['End_Time'])

data2.shape

data.head(10)

Data_club = pd.DataFrame(data2.groupby([data2['End_Time'].dt.year.rename('year'), data2['End_Time'].dt.month.rename('month')]).agg({'count'}))

Data_club = Data_club.iloc[:,0]

Data_club.unstack(level=0).plot(kind='line', subplots=False)

Data_club_day = data2.groupby([data2['End_Time'].dt.year.rename('year'), data2['End_Time'].dt.dayofweek.rename('Day')]).agg({'count'})

Data_club_day=Data_club_day.iloc[:,0]

Data_club_day.unstack(level=0).plot(kind='line', subplots=False)

"""Visualization on the year"""

time_df = pd.DataFrame(data.End_Time.dt.year.value_counts()).reset_index().rename(columns={'index':'Year', 'End_Time':'Cases'}).sort_values(by='Year', ascending=True)

time_df

time_df = time_df.iloc[0:5,:]

import matplotlib.pyplot as plt
plt.figure(figsize = (12,7))
plt.bar(time_df['Year'], time_df['Cases'], width= 0.5, align='center',color='cyan', edgecolor = 'red')
# Creating the legend of the bars in the plot
plt.legend(labels = ['Total Accidents'])
# Giving the tilte for the plot
plt.title("Bar plot representing the accidents over the years")
# Namimg the x and y axis
plt.xlabel('Year')
plt.ylabel('Number of Accidents')
plt.xticks([2016,2017,2018,2019,2020])
# Saving the plot as a 'png'
plt.savefig('0BarPlot.png')
# Displaying the bar plot
plt.show()

"""Visualization based on day of week """

year_df = pd.DataFrame(data.End_Time.dt.day_name().value_counts()).reset_index().rename(columns={'index':'DayOfWeek', 'End_Time':'Cases'}).sort_values(by='DayOfWeek', ascending=True)

year_df['DayOfWeek'] = pd.Categorical(year_df['DayOfWeek'], categories=
    ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],
    ordered=True)

year_df = year_df.sort_values(by='DayOfWeek', ascending=True)

print(year_df)

import matplotlib.pyplot as plt
plt.figure(figsize = (12,7))
plt.bar(year_df['DayOfWeek'], year_df['Cases'], width= 0.8, align='center',color='turquoise', edgecolor = 'red')
# Creating the legend of the bars in the plot
plt.legend(labels = ['Total Accidents'])
# Giving the tilte for the plot
plt.title("Bar plot representing the accidents corresponding to the days in a week")
# Namimg the x and y axis
plt.xlabel('Days of Week')
plt.ylabel('Number of Accidents')
# Saving the plot as a 'png'
plt.savefig('1BarPlot.png')
# Displaying the bar plot
plt.show()



"""Visualization based on Month of year"""

month_df = pd.DataFrame(data.End_Time.dt.month_name().value_counts()).reset_index().rename(columns={'index':'Month', 'End_Time':'Cases'}).sort_values(by='Cases', ascending=True)

month_df['Month'] = pd.Categorical(month_df['Month'], categories=
    ['January','February','March','April','May','June','July','August','Septmenber','October','November','December'],
    ordered=True)

month_df = month_df.sort_values(by='Month', ascending=True)

month_df=month_df.dropna()

#month_df = month_df.astype(int)
plt.figure(figsize = (12,7))
plt.barh(month_df['Month'], month_df['Cases'], label = "Danger zone", color = 'r')
# Creating the legend of the bars in the plot
plt.legend(labels = ['Total Accidents'])
# Giving the tilte for the plot
plt.title("Bar plot representing the accidents reported in different months of year")
# Namimg the x and y axis
plt.xlabel('Number of Accidents')
plt.ylabel('Months')
# Saving the plot as a 'png'
plt.savefig('2BarPlot.png')
# Displaying the bar plot
plt.show()

"""Visualization based on Time of the Day"""

hour_df = pd.DataFrame(data.End_Time.dt.hour.value_counts()).reset_index().rename(columns={'index':'Time of Day', 'End_Time':'Cases'}).sort_values(by='Time of Day', ascending=True)

hour_df

import matplotlib.pyplot as plt
plt.figure(figsize = (12,7))
plt.bar(hour_df['Time of Day'], hour_df['Cases'], width= 0.8, align='center',color='cyan', edgecolor = 'red')
# Creating the legend of the bars in the plot
plt.legend(labels = ['Total Accidents'])
# Giving the tilte for the plot
plt.title("Bar plot representing the accidents corresponding to the hours in a day")
# Namimg the x and y axis
plt.xlabel('Hours in a day')
plt.ylabel('Number of Accidents')
# Saving the plot as a 'png'
plt.savefig('3BarPlot.png')
# Displaying the bar plot
plt.show()

data_multi_ym = data['End_Time'].groupby([data.End_Time.dt.year, data.End_Time.dt.month]).agg('count')

data_multi_ym

# Removing 2021 entries

data_multi_ym.unstack(level=0).plot(kind='line', subplots=False, figsize=(12,7))

data_weather_days = data.groupby(data['End_Time'].dt.day_name()).mean()

data_weather_days

data_weather_month = data.groupby(data['End_Time'].dt.month_name()).mean()

data_weather_month= data_weather_month.iloc[:,2:8]

data_weather_month

data.info()

data_states_weather = data.iloc[:,7:16]

data_states_weather = data_states_weather.groupby(data_states_weather['State']).mean()

data_states_weather= pd.merge(data_states_weather,states_data, on="State")
# join with state and accident count to find patterns

data_states_weather.sort_values(by="Cases",ascending=False).head(10)

data_states_weather.sort_values(by="Temperature(F)",ascending=False).head(10)

"""**Insights **
1. The states that are more prone to accidents are actually warmer i.e they have their temperatures higher than the average temperature. 
2. Months 
3. Days
4. The states on the west experience greater number of accidents than those on the east, but in terms of severity, the accidents are more severe in the east US than the west US. 
5. Time of Day
6. Road Structure 
7. Predicting the severity of the accidents based on road structure and weather conditions. 
8. Applied PCA on the data
9. K-means ? 
"""

data_states_weather.describe()



data_states_weather.info()

# Road Structure Visualization + Severity analysis 
data_road = data.loc[:,['Severity','Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop']]

data_road.info()

data.groupby(['Severity','Junction']).size().unstack(fill_value=0).plot.bar()



data_road.groupby(by = "Severity").count().plot(kind = "bar")

# Supervised Learning Algorithm
#predicting the severity of the accident based on the weather conditions and road structure
data.info()

data1 = data.drop(['Weather_Condition','Wind_Direction'],1)
data1=data1.dropna()
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
Xdata_ml = data1.iloc[:,9:34]
Ydata_ml = data1.iloc[:,1]
X_train = Xdata_ml.to_numpy()
y_train = Ydata_ml.to_numpy()
for i in range(len(X_train)):
  if(X_train[i][-3]=='Night'):
    X_train[i][-3]=0
  else:
    X_train[i][-3]=1

data1.info()

Xdata_ml.info()

upper_limit= (int)(len(X_train)*0.80)
X_train1 = X_train[:upper_limit,:]
y_train1 = y_train[:upper_limit]
X_test = X_train[upper_limit+1:,:]
y_test = y_train[upper_limit+1:]

# Multi-class Classification 
# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train1,y_train1)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

X_train.shape

# Random Forest Classifier 
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100)
clf = clf.fit(X_train1, y_train1)
y_pred = clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# ADA Boost Classifier
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier(n_estimators=100)
scores = cross_val_score(clf, X_train1, y_train1, cv=5)
scores.mean()
clf.fit(X_train1, y_train1)
y_pred = clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# unsupervised learning
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import normalize
from sklearn.decomposition import PCA
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
  
# Normalizing the data so that 
# the data approximately follows a Gaussian distribution
X_normalized = normalize(X_scaled)
  
# Converting the numpy array into a pandas DataFrame
X_normalized = pd.DataFrame(X_normalized)

pca = PCA(n_components = 9)
X_principal = pca.fit_transform(X_normalized)
X_principal = pd.DataFrame(X_principal)
X_principal.columns = ['P1','P2','P3','P4','P5','P6','P7','P8','P9']
print(X_principal.head())

print(pca.explained_variance_ratio_)

sum(pca.explained_variance_ratio_)

print(abs( pca.components_ ))

# pie chart visualization 

import numpy as np
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (10,25))

road_conditions = ['Bump', 'Crossing','Junction', 'Traffic_Signal', 'Turning_Loop']
colors = [('#6662b3', '#00FF00'), ('#7881ff', '#0e1ce8'), ('#18f2c7', '#09ad8c'), ('#08ff83', '#02a352'), ('#ffcf87', '#f5ab3d'),
         ('#f5f53d', '#949410'), ('#ff9187', '#ffc7c2'), ('tomato', '#008000')]    
count = 0

def func(pct, allvals):
    absolute = int(round(pct/100*np.sum(allvals), 2))
    return "{:.2f}%\n({:,d} Cases)".format(pct, absolute)    

for i in [ax1, ax2, ax3, ax4]:
    
    size = list(data[road_conditions[count]].value_counts())
    if len(size) != 2:
        size.append(0)
    
    labels = ['False', 'True']

    i.pie(size, labels = labels, colors = colors[count],
                    autopct = lambda pct: func(pct, size), labeldistance=1.1,
                    textprops={'fontsize': 12}, explode=[0, 0.2])

    title = '\nPresence of {}'.format(road_conditions[count])

    i.set_title(title, fontsize = 18, color='grey')
    
    count += 1

